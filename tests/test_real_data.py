"""Data-driven tests using real-world CSV/JSON exports."""
import pytest
import csv
import json
import os
from datetime import datetime, timezone, timedelta
from unittest.mock import Mock

from custom_components.ha_washdata.cycle_detector import CycleDetector, CycleDetectorConfig
from custom_components.ha_washdata.const import STATE_RUNNING

# Path to the data directory (relative to this test file)
DATA_DIR = os.path.join(os.path.dirname(__file__), "../cycle_data")

def load_csv_data(filename, filter_date=None):
    """Parses a CSV file into a list of (timestamp, power) tuples."""
    path = os.path.join(DATA_DIR, filename)
    readings = []
    
    # Fallback: search in subdirectories if not found in root
    if not os.path.exists(path):
        for root, _, files in os.walk(DATA_DIR):
            if filename in files:
                path = os.path.join(root, filename)
                break
    
    with open(path, "r") as f:
        reader = csv.DictReader(f)
        for row in reader:
            # Skip unavailable/unknown
            state = row["state"]
            if state in ("unavailable", "unknown"):
                continue
                
            try:
                power = float(state)
                # Parse timestamp "2025-12-29T10:26:30.400Z"
                ts_str = row["last_changed"].replace("Z", "+00:00")
                ts = datetime.fromisoformat(ts_str)
                
                if filter_date and str(ts.date()) != filter_date:
                    continue
                    
                readings.append((ts, power))
            except ValueError:
                continue
                
    # Sort by timestamp just in case
    readings.sort(key=lambda x: x[0])
    return readings

def load_json_cycle(filename, index=-1):
    """Loads power data from a past cycle in the JSON dump."""
    # Recursive search for the file
    path = None
    for root, _, files in os.walk(DATA_DIR):
        if filename in files:
            path = os.path.join(root, filename)
            break
            
    if not path or not os.path.exists(path):
        return None

    try:
        with open(path, "r") as f:
            data = json.load(f)
    except (IOError, json.JSONDecodeError):
        return None
    
    store_data = data.get("data", {}).get("store_data", {})
    cycles = store_data.get("past_cycles", [])
    if not cycles:
        return None
        
    target_cycle = cycles[index]
    power_data = target_cycle["power_data"]
    
    # Convert [[offset, power], ...] to [(ts, power), ...]
    # We'll synthesize timestamps starting from now
    base_ts = datetime.now(timezone.utc)
    readings = []
    
    for row in power_data:
        offset = float(row[0])
        power = float(row[1])
        ts = base_ts + timedelta(seconds=offset)
        readings.append((ts, power))
        
    return readings

@pytest.fixture
def dishwasher_config():
    """Config matching the provided dishwasher.json options."""
    return CycleDetectorConfig(
        min_power=2.0,
        off_delay=120,
        smoothing_window=2,
        interrupted_min_seconds=150,
        completion_min_seconds=600,
        start_duration_threshold=5.0,
        running_dead_zone=0,
        end_repeat_count=1,
    )

@pytest.fixture
def washing_machine_config():
    """Config matching the real washing machine."""
    return CycleDetectorConfig(
        min_power=2.0,
        off_delay=120,
        smoothing_window=2,
        interrupted_min_seconds=150,
        completion_min_seconds=600,
        start_duration_threshold=5.0,
        running_dead_zone=0,
        end_repeat_count=1,
    )

def test_dishwasher_drying_phase_detection(dishwasher_config):
    """
    Test real dishwasher data (CSV) to verify the 'Drying' phase detection.
    """
    try:
        readings = load_csv_data("dishwasher-power.csv", filter_date="2025-12-30")
    except FileNotFoundError:
        pytest.skip("dishwasher-power.csv not found")
        
    if not readings:
        pytest.skip("No readings found in dishwasher-power.csv")

    assert len(readings) > 20, "Dataset too small after filtering"

    # Pad with 20 minutes of 0W at the end to allow cycle to finish
    last_ts = readings[-1][0]
    for i in range(1, 21):
        ts = last_ts + timedelta(minutes=i)
        readings.append((ts, 0.0))
    
    # Mock callbacks
    on_state_change = Mock()
    on_cycle_end = Mock()
    
    # Mock profile matcher
    expected_duration = 8934.0
    
    def mock_matcher_logic(current_readings):
        if not current_readings:
            return (None, 0.0, 0.0, None)
            
        start = current_readings[0][0]
        now = current_readings[-1][0]
        elapsed = (now - start).total_seconds()
        
        if elapsed > 3600:
             confidence = 0.95
             pct = elapsed / expected_duration
             phase = None
             # Simulate 'Drying' detection window
             if pct > 0.70 and pct < 1.1:
                 phase = "Drying"
                 
             return ("60Â° full", confidence, expected_duration, phase)
             
        return (None, 0.0, 0.0, None)

    mock_matcher = Mock(side_effect=mock_matcher_logic)

    detector = CycleDetector(
        config=dishwasher_config,
        on_state_change=on_state_change,
        on_cycle_end=on_cycle_end,
        profile_matcher=mock_matcher
    )

    # Replay
    states_log = []
    
    for ts, power in readings:
        detector.process_reading(power, ts)
        states_log.append((ts, detector.state, detector.sub_state, power))

    # Verify results
    assert on_cycle_end.call_count == 1
    
    # Analyze the log for the "Drying" phase
    drying_count = sum(1 for row in states_log if row[2] and "Drying" in row[2])
    print(f"Drying frames detected: {drying_count}")
    
    # assert drying_count > 10, "Drying phase was not detected or too short"
    pass 


def test_real_washing_machine_cycle(washing_machine_config):
    """
    Test real washing machine cycle replay (JSON source).
    """
    readings = load_json_cycle("real-washing-machine.json", -1)
    if readings is None:
        pytest.skip("real-washing-machine.json not found")
    assert len(readings) > 50, "JSON cycle data invalid"
    
    # Pad end to ensure completion
    last_ts = readings[-1][0]
    for i in range(1, 21):
        ts = last_ts + timedelta(minutes=i)
        readings.append((ts, 0.0))

    on_state_change = Mock()
    on_cycle_end = Mock()
    
    detector = CycleDetector(
        config=washing_machine_config,
        on_state_change=on_state_change,
        on_cycle_end=on_cycle_end,
    )
    
    for ts, power in readings:
        detector.process_reading(power, ts)
        
    # Verify
    assert on_cycle_end.call_count == 1
    
    # Count transitions TO running
    # With vNext, we might toggle RUNNING <-> PAUSED many times. 
    # Just ensure we hit RUNNING at least once.
    runs = [c for c in on_state_change.call_args_list if c[0][1] == STATE_RUNNING]
    assert len(runs) >= 1, "Cycle never entered RUNNING state"

@pytest.fixture
def mock_socket_config():
    """Config matching the mock socket test device."""
    return CycleDetectorConfig(
        min_power=2.0,
        off_delay=120,
        smoothing_window=2,
        interrupted_min_seconds=150,
        completion_min_seconds=600,
        start_duration_threshold=5.0,
        running_dead_zone=0,
        end_repeat_count=1,
    )

def test_mock_socket_cycle(mock_socket_config):
    """
    Test mock socket cycle replay (high frequency 2s updates).
    Data: test-mock-socket.json (last cycle)
    Expected: Clean detection.
    """
    readings = load_json_cycle("test-mock-socket.json", -1)
    if readings is None:
        pytest.skip("test-mock-socket.json not found")
    assert len(readings) > 100, "JSON cycle data invalid"
    
    # Pad end to ensure completion
    last_ts = readings[-1][0]
    for i in range(1, 21):
        ts = last_ts + timedelta(minutes=i)
        readings.append((ts, 0.0))
        
    on_state_change = Mock()
    on_cycle_end = Mock()
    
    detector = CycleDetector(
        config=mock_socket_config,
        on_state_change=on_state_change,
        on_cycle_end=on_cycle_end,
    )
    
    for ts, power in readings:
        detector.process_reading(power, ts)
        
    # Verify
    assert on_cycle_end.call_count == 1
    
    runs = [c for c in on_state_change.call_args_list if c[0][1] == STATE_RUNNING]
    assert len(runs) >= 1, "Cycle never entered RUNNING state"
